{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# univariate multi-step encoder-decoder cnn-lstm for the power usage dataset\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import pdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(n_input):\n",
    "    data = SCALED_DATA\n",
    "    for i in range(STEPS):\n",
    "        data = np.delete(data, -1, 0)\n",
    "    \n",
    "    number_of_rows = len(data)\n",
    "    train_number = (number_of_rows * TRAIN_PERCENTAGE) / 100\n",
    "    test_number = (number_of_rows * TEST_PERCENTAGE) / 100\n",
    "\n",
    "\n",
    "    while True:\n",
    "        if train_number % n_input == 0 and test_number % n_input == 0:\n",
    "            break\n",
    "        else:\n",
    "            number_of_rows = number_of_rows - 1\n",
    "            train_number = (number_of_rows * TRAIN_PERCENTAGE) / 100\n",
    "            test_number = (number_of_rows * TEST_PERCENTAGE) / 100\n",
    "\n",
    "    print(train_number)\n",
    "    print(test_number)\n",
    "    total_valid_count = int(train_number + test_number)\n",
    "    print(total_valid_count)\n",
    "    rows_to_remove = len(data) - total_valid_count\n",
    "    print(rows_to_remove)\n",
    "\n",
    "    data = data[rows_to_remove:]\n",
    "    number_of_rows = len(data)\n",
    "    train_number = int((number_of_rows * TRAIN_PERCENTAGE) / 100)\n",
    "    test_number = int((number_of_rows * TEST_PERCENTAGE) / 100)\n",
    "    \n",
    "    train = data[:train_number]\n",
    "    test = data[train_number:]\n",
    "    print(f'Train length {len(train)}')\n",
    "    print(f'Test length {len(test)}')\n",
    "\n",
    "    train = array(split(train, len(train)/n_input))\n",
    "    test = array(split(test, len(test)/n_input))\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train, config):\n",
    "    n_input, epochs, batch_size, conv1, conv2 = config[0], config[1], config[2], config[3], config[4]\n",
    "    lstm, dense, conv_layer = config[5], config[6], config[7]\n",
    "    \n",
    "    train_x, train_y = to_supervised(train, n_input, STEPS)\n",
    "    verbose = 0\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1] \n",
    "\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(conv1, conv_layer, activation='relu', input_shape=(n_timesteps,n_features))) \n",
    "    model.add(Conv1D(conv2, conv_layer, activation='relu'))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(lstm, activation='relu', return_sequences=True)) \n",
    "    model.add(TimeDistributed(Dense(dense, activation='relu'))) \n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    if SAVE_MODEL:\n",
    "        pickle.dump(model, open(MODEL_NAME, 'wb'))\n",
    "        pickle.dump(PRICE_SCALER, open('price_scaler.sav', 'wb'))\n",
    "        pickle.dump(SCALER, open('scaler.sav', 'wb'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(train, test, config):\n",
    "    dataset = SCALED_DATA\n",
    "    n_input = config[0]\n",
    "    \n",
    "    model = build_model(train, config)\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    actual = []\n",
    "\n",
    "    unscaled_test_prices = PRICE_SCALER.inverse_transform(test[:, :, 0])\n",
    "    unscaled_test_prices = unscaled_test_prices.reshape(len(test), test.shape[1], 1)\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        history.append(test[i, :])\n",
    "        if len(test) > 1 and i > 0:\n",
    "            actual = np.append(actual, unscaled_test_prices[i][:STEPS,0])\n",
    "\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        predictions.append(yhat_sequence)\n",
    "        \n",
    "    predictions = array(predictions).reshape(len(predictions), STEPS)\n",
    "    predictions = PRICE_SCALER.inverse_transform(predictions)\n",
    "    \n",
    "    last_actual_price = PRICE_SCALER.inverse_transform(dataset[-STEPS:,0].reshape(1,STEPS))\n",
    "    actual = np.append(actual, last_actual_price)\n",
    "    actual = actual.reshape(len(predictions), STEPS)\n",
    "    \n",
    "    score, scores = evaluate_forecasts(actual, predictions)\n",
    "    return score, actual, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    for i in range(STEPS):\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "     #   print(f'TEST actual price {actual[:, i]}!')\n",
    "     #   print(f'TEST predicted price {predicted[:, i]}!')\n",
    "        rmse = sqrt(mse)\n",
    "        scores.append(rmse)\n",
    "    s=0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, history, n_input):\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\n",
    "    input_x = data[-n_input:, :]\n",
    "    input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "    #pdb.set_trace()\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    yhat = yhat.reshape(1,STEPS)\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_out):\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "\n",
    "    for _ in range(len(data)):\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        \n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "            \n",
    "        in_start += 1\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores]) \n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    n_input = [10]\n",
    "    n_epochs = [95]\n",
    "    n_batch = [450] \n",
    "    conv1 = [220]\n",
    "    conv2 = [180]\n",
    "    lstm = [100]\n",
    "    dense = [180]\n",
    "    conv_layer = [4]\n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for i in n_input:\n",
    "        for j in n_epochs:\n",
    "            for k in n_batch:\n",
    "                for l in conv1:\n",
    "                    for m in conv2:\n",
    "                        for n in lstm:\n",
    "                            for p in dense:\n",
    "                                for q in conv_layer:\n",
    "                                    cfg = [i, j, k, l, m, n, p, q]\n",
    "                                    configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs)) \n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_evaluate(train, test, config, times=30):\n",
    "    scores = 0\n",
    "    all_actuals, all_predictions = [], []\n",
    "    for _ in range(times):\n",
    "        score, actual, predictions = evaluate_model(train, test, config)\n",
    "        all_actuals.append(actual)\n",
    "        all_predictions.append(predictions)\n",
    "        scores += score\n",
    "    \n",
    "    average_score = scores / times\n",
    "    print(f'Average score {average_score}')\n",
    "    \n",
    "    print(f'Last actual prices {all_actuals[-1][-8:]}')\n",
    "    print(f'Last predicted prices {all_predictions[-1][-8:]}')\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 1\n",
      "CONFIGS 1\n",
      "CONFIG NUMBER 1\n",
      "6540.0\n",
      "2180.0\n",
      "8720\n",
      "27\n",
      "Train length 6540\n",
      "Test length 2180\n",
      "Average score 10.821406637753379\n",
      "Last actual prices [[12582. ]\n",
      " [12664. ]\n",
      " [12629.8]\n",
      " [12635.5]\n",
      " [12641.5]\n",
      " [12652.3]\n",
      " [12643.5]\n",
      " [12634.9]]\n",
      "Last predicted prices [[12571.673]\n",
      " [12656.981]\n",
      " [12626.987]\n",
      " [12627.821]\n",
      " [12646.622]\n",
      " [12651.83 ]\n",
      " [12650.816]\n",
      " [12635.155]]\n",
      "Best score [10.821406637753379, 10, 95, 450, 220, 180, 100, 180, 4]\n",
      "All scores [[10.821406637753379, 10, 95, 450, 220, 180, 100, 180, 4]]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PERCENTAGE = 75\n",
    "TEST_PERCENTAGE = 25\n",
    "STEPS = 1\n",
    "REPEAT = 1\n",
    "SAVE_MODEL = False\n",
    "MODEL_NAME = 'LSTM_1_step.sav'\n",
    "\n",
    "SCALER = StandardScaler()\n",
    "PRICE_SCALER = StandardScaler()\n",
    "\n",
    "dataset = read_csv('dax_5_train.csv', header=0, infer_datetime_format=False, parse_dates=['price_date'], index_col=['price_date'])\n",
    "dataset = dataset.round(2)\n",
    "normal_values = dataset.values[:, 1:]\n",
    "price_values = dataset.values[:, 0]\n",
    "price_values = price_values.reshape(len(price_values), 1)\n",
    "\n",
    "PRICE_SCALER = PRICE_SCALER.fit(price_values)\n",
    "SCALER = SCALER.fit(normal_values)\n",
    "\n",
    "SCALED_PRICES = PRICE_SCALER.transform(price_values)\n",
    "SCALED_NORMAL = SCALER.transform(normal_values)\n",
    "\n",
    "SCALED_DATA = np.column_stack((SCALED_PRICES, SCALED_NORMAL))\n",
    "\n",
    "configs = model_configs()\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "scores = []\n",
    "print(f'CONFIGS {len(configs)}')\n",
    "i = 0\n",
    "for config in configs:\n",
    "    i += 1\n",
    "    print(f'CONFIG NUMBER {i}')\n",
    "    n_input = config[0]\n",
    "    train, test = split_dataset(n_input)\n",
    "    score = repeat_evaluate(train, test, config, REPEAT)\n",
    "    config.insert(0, score)\n",
    "    scores.append(config)\n",
    "\n",
    "scores.sort(key = lambda scores: scores[0])\n",
    "print(f'Best score {scores[0]}')\n",
    "print(f'All scores {scores}')\n",
    "\n",
    "\n",
    "#score, scores, model = evaluate_model(train, test, config)\n",
    "\n",
    "#repeat_evaluate(data, config, n_test)\n",
    "\n",
    "#summarize_scores('lstm', score, scores)\n",
    "#pyplot.plot(scores, marker='o', label='lstm') \n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9919784062012623\n"
     ]
    }
   ],
   "source": [
    "test_value = test[0].reshape(STEPS,10,21)\n",
    "print(test[1][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(scaler.transform(test[1]))\n",
    "\n",
    "#print(encode_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scaler.inverse_transform(encode_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12057.37021315]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[11968.779]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'LSTM_1_step.sav'\n",
    "loaded_model = pickle.load(open(MODEL_NAME, 'rb'))\n",
    "predicted_price = loaded_model.predict(test_value)\n",
    "print(PRICE_SCALER.inverse_transform(test[1][0][1].reshape(1,1)))\n",
    "PRICE_SCALER.inverse_transform(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[12656.607]]]\n",
      "[[[12626.908]]]\n",
      "[[ 2.17015422  1.44500499 -1.35848781  1.33695231 -1.29027577 -1.03391388\n",
      "  -0.97457853 -0.40739564  0.18208831  2.19836513  2.18472879  2.17237978\n",
      "   2.17437232 -0.50370096 -0.70185368  2.172128   -0.49124932 -0.647236\n",
      "  -1.10601423 -1.86362254 -0.49708764]\n",
      " [ 2.18256258  1.17422906 -0.53940645  0.82447931 -1.29027577 -0.75729327\n",
      "  -0.42330218 -0.354462    0.41525944  2.19658161  2.18494477  2.17129883\n",
      "   2.18352463 -0.39451565 -0.15421556  2.16943047 -0.36424864 -0.12015234\n",
      "  -0.51556234 -0.58035213 -0.60792167]\n",
      " [ 2.20414232  0.90345312 -0.81243357  0.31200631  1.27304631 -0.40306522\n",
      "   0.34007759 -0.50363863 -0.17797428  2.19906773  2.19228814  2.18859404\n",
      "   2.19321532 -0.15014852  0.20607268  2.18399713 -0.17374762  0.23123677\n",
      "   0.28328435  0.63078333 -0.53134544]\n",
      " [ 2.18795751  0.63267719 -1.08546069 -0.20046669  1.27304631 -0.86678893\n",
      "  -0.5317605  -0.66243956 -0.41307777  2.19814894  2.19180218  2.1983226\n",
      "   2.18513975 -0.39451565  0.06195739  2.20557735 -0.36424864  0.05554221\n",
      "  -0.28328898 -0.25156309 -0.32176836]\n",
      " [ 2.18526004  0.36190126 -1.35848781 -0.71293969  0.76038189 -0.86678893\n",
      "  -0.55165523 -0.80519999 -0.60180467  2.19690588  2.19056029  2.18589167\n",
      "   2.19698392 -0.35812054  0.13401503  2.18669465 -0.36424864  0.14338949\n",
      "  -0.37156733 -0.37962877 -0.54343642]\n",
      " [ 2.16475929  0.09112533 -1.35848781 -1.22541269  0.24771748 -0.93248633\n",
      "  -0.50031401 -0.85171743 -0.72032259  2.19214983  2.18289295  2.17237978\n",
      "   2.18083278 -0.58169047 -0.1037752   2.18669465 -0.55474966 -0.12015234\n",
      "  -0.96563719 -1.14645472 -0.55754257]\n",
      " [ 2.15828537  1.44500499 -1.35848781  1.33695231 -0.26494694 -0.97167424\n",
      "  -0.99960737 -0.78996152 -0.53159569  2.18712355  2.17560358  2.16967741\n",
      "   2.16629675 -0.36851914 -0.35597697  2.16403541 -0.36424864 -0.38369417\n",
      "  -1.12699843 -1.32470124 -0.23511631]\n",
      " [ 2.15127195  1.44500499  0.2796749   1.33695231 -0.77761135 -1.05466043\n",
      "  -1.42798568 -0.72419548 -0.35317469  2.1816649   2.16842221  2.15778695\n",
      "   2.16468164 -0.38411705 -0.7378825   2.15702184 -0.36424864 -0.73508328\n",
      "  -1.29776638 -1.50922036 -0.22705565]\n",
      " [ 2.12591575  1.44500499  0.00664778  1.33695231 -1.29027577 -1.3827632\n",
      "  -1.42798568 -0.51967913  0.09384399  2.17263921  2.15519335  2.15616552\n",
      "   2.13776307 -0.57649116 -0.8603805   2.15054777 -0.55474966 -0.82293056\n",
      "  -1.80428149 -1.95509803  0.04902184]\n",
      " [ 2.1555879   1.44500499  1.37178336  1.33695231  1.27304631 -1.30515576\n",
      "  -1.34198913 -0.45631916  0.16276474  2.17063951  2.15627326  2.2664225\n",
      "   2.13184098 -0.21254013 -0.42803462  2.1246515  -0.23724796 -0.38369417\n",
      "  -0.66534609 -0.34512944 -0.66636143]]\n"
     ]
    }
   ],
   "source": [
    "price_scaler = pickle.load(open('price_scaler.sav', 'rb'))\n",
    "to_predict = test[-1].reshape(1, 10,21)\n",
    "#print(price_scaler.inverse_transform(to_predict))\n",
    "prediction = loaded_model.predict(to_predict)\n",
    "print(PRICE_SCALER.inverse_transform(prediction))\n",
    "print(price_scaler.inverse_transform(prediction))\n",
    "#print(price_scaler.inverse_transform(test[-1]))\n",
    "print(test[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12450.0],\n",
       " [12433.2],\n",
       " [12438.5],\n",
       " [12439.7],\n",
       " [12444.7],\n",
       " [12435.7],\n",
       " [12439.8],\n",
       " [12466.5],\n",
       " [12465.5],\n",
       " [12465.5],\n",
       " [12430.2],\n",
       " [12385.5]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([[12450. ],\n",
    "       [12433.2],\n",
    "       [12438.5],\n",
    "       [12439.7],\n",
    "       [12444.7],\n",
    "       [12435.7],\n",
    "       [12439.8],\n",
    "       [12466.5],\n",
    "       [12465.5],\n",
    "       [12465.5],\n",
    "       [12430.2],\n",
    "       [12385.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
